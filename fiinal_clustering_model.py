# -*- coding: utf-8 -*-
"""fiinal clustering model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cAlX1hmHDBNsQWN1kB_JePso7kjS-qmm
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings as warn
warn.filterwarnings('ignore')
import zipfile
path=zipfile.ZipFile('/content/archive (3).zip','r')
with path.open('Spotify-2000.csv') as f:
  df= pd.read_csv(f)
display(df.head())

df.shape
df.info()
df.describe()

df=df.drop('Index',axis=1)
df['Length (Duration)'] = df['Length (Duration)'].str.replace(',', '').astype(int)
numerical=['Year', 'Beats Per Minute (BPM)',
       'Energy', 'Danceability', 'Loudness (dB)', 'Liveness', 'Valence',
       'Length (Duration)', 'Acousticness', 'Speechiness', 'Popularity']
df[numerical].corr()

# Drop Loudness and Acousticness based on correlation logic
df = df.drop(columns=['Loudness (dB)', 'Acousticness'])

sns.histplot(df['Energy'], kde=True)

top_titles = df['Title'].value_counts().nlargest(10)

sns.barplot(x=top_titles.values, y=top_titles.index)
plt.title("Top 10 Most Frequent Titles")
plt.xlabel("Count")
plt.ylabel("Title")
plt.show()

top_titles = df['Artist'].value_counts().nlargest(10)

sns.barplot(x=top_titles.values, y=top_titles.index)
plt.title("Top 10 Most Frequent Artist")
plt.xlabel("Count")
plt.ylabel("Artist")
plt.show()

top_titles = df['Top Genre'].value_counts().nlargest(10)

sns.barplot(x=top_titles.values, y=top_titles.index)
plt.title("Top 10 Most Frequent Top Genre")
plt.xlabel("Count")
plt.ylabel("Top Genre")
plt.show()

numeric_cols = ['Energy', 'Danceability', 'Valence', 'Popularity',
                'Beats Per Minute (BPM)', 'Speechiness', 'Liveness',
                'Length (Duration)']

for col in numeric_cols:
    plt.figure(figsize=(6, 4))
    sns.histplot(df[col], kde=True)
    plt.title(f"Distribution of {col}")
    plt.show()

df[numeric_cols].skew()

from sklearn.preprocessing import PowerTransformer

# Select columns to transform
skewed_cols = ['Liveness', 'Speechiness','Length (Duration)']

# Apply Yeo-Johnson (works for all values)
pt = PowerTransformer(method='yeo-johnson')
df[skewed_cols] = pt.fit_transform(df[skewed_cols])

df[skewed_cols]

df[numeric_cols].skew()  # Should now be close to 0

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler_df=['Energy', 'Danceability', 'Valence', 'Popularity',
                'Beats Per Minute (BPM)']
df[scaler_df] = scaler.fit_transform(df[scaler_df])

df[scaler_df]

numeric_cols = ['Energy', 'Danceability', 'Valence', 'Popularity',
                'Beats Per Minute (BPM)', 'Speechiness', 'Liveness',
                'Length (Duration)']

for col in numeric_cols:
    plt.figure(figsize=(6, 4))
    sns.histplot(df[col], kde=True)
    plt.title(f"Distribution of {col}")
    plt.show()

from sklearn.cluster import KMeans
inertias = []
K = range(1, 11)

for k in K:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(df[numeric_cols])
    inertias.append(kmeans.inertia_)

# Plot the Elbow Curve
plt.figure(figsize=(8, 4))
plt.plot(K, inertias, 'bo-')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Inertia')
plt.title('Elbow Method For Optimal k')
plt.show()

df_original = df[numeric_cols].copy()
df_original[skewed_cols] = pt.inverse_transform(df[skewed_cols])

# Apply KMeans with your chosen number of clusters
kmeans = KMeans(n_clusters=6, random_state=42)
Cluster= kmeans.fit_predict(df_original[skewed_cols])

df["Music Segments"] = Cluster
df["Music Segments"] = df["Music Segments"].map({
    0: "Cluster 1", 1: "Cluster 2", 2: "Cluster 3", 3: "Cluster 4",
    4: "Cluster 5", 5: "Cluster 6", 6: "Cluster 7", 7: "Cluster 8"
})

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import PCA

# Reduce to 2 components for 2D visualization
pca = PCA(n_components=2)
pca_result = pca.fit_transform(df_original[skewed_cols])

# Add PCA results to DataFrame
df['PCA1'] = pca_result[:, 0]
df['PCA2'] = pca_result[:, 1]

# Create the scatter plot
plt.figure(figsize=(10, 6))
sns.scatterplot(
    data=df,
    x='PCA1',
    y='PCA2',
    hue='Music Segments',  # this shows all 8 clusters with names
    palette='tab10',
    s=70,
    alpha=0.8
)

plt.title("üéµ Music Clustering (PCA View with 6 Clusters)", fontsize=14)
plt.xlabel("PCA Component 1")
plt.ylabel("PCA Component 2")
plt.legend(title='Cluster Label', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True)
plt.tight_layout()
plt.show()

# Get PCA of cluster centers
pca_centers = pca.transform(kmeans.cluster_centers_)

# Add cluster centers to the plot
plt.scatter(
    pca_centers[:, 0],
    pca_centers[:, 1],
    c='black',
    s=200,
    alpha=0.7,
    marker='X',
    label='Centroids'
)

kmeans = KMeans(n_clusters=6)
clusters = kmeans.fit_predict(df_original[skewed_cols])

import matplotlib.pyplot as plt

# Use 2D PCA for visualization
from sklearn.decomposition import PCA
X_pca = PCA(n_components=2).fit_transform(df_original[skewed_cols])

# Plot clusters
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='tab10', s=100, alpha=0.6)

# Plot centroids
centroids = kmeans.cluster_centers_
centroids_pca = PCA(n_components=2).fit(df_original[skewed_cols]).transform(centroids)

plt.scatter(centroids_pca[:, 0], centroids_pca[:, 1],
            c='black', s=200, marker='X', label='Centroids')

plt.title("Clusters with Centroids")
plt.legend()
plt.show()

df.groupby("Music Segments")[numeric_cols].mean().round(2)

def recommend_songs(df, song_title, n=5):
    # Case-insensitive match
    match = df[df['Title'].str.lower() == song_title.lower()]

    # If song not found, return a message
    if match.empty:
        return f"‚ùå Song titled '{song_title}' not found in the dataset."

    # Get the cluster number
    song_cluster = match['Music Segments'].values[0]

    # Get all songs from the same cluster (excluding the input song itself)
    recommendations = df[(df['Music Segments'] == song_cluster) & (df['Title'].str.lower() != song_title.lower())]

    # Handle case where fewer than n songs are available
    if len(recommendations) == 0:
        return "‚ö†Ô∏è No other songs found in the same cluster."

    return recommendations.sample(min(n, len(recommendations)))[['Title', 'Artist', 'Top Genre', 'Music Segments']]

recommend_songs(df, "Without Me", n=5)

df['Top Genre'].value_counts().head(10)

df.groupby('Music Segments')['Top Genre'].value_counts().groupby(level=0).head(3)

